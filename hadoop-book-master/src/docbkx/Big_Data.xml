<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xml:id="Big_Data" xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:svg="http://www.w3.org/2000/svg"
    xmlns:m="http://www.w3.org/1998/Math/MathML"
    xmlns:html="http://www.w3.org/1999/xhtml"
    xmlns:db="http://docbook.org/ns/docbook">

    <title>Big Data</title>
    <sect1>
        <title>What is Big Data?</title>
        <para>
            You probably heard the term Big Data -- it is one of the most hyped terms now.  But what exactly is big data?
        </para>
        <para>
            Big Data is very large, loosely structured data set that defies traditional storage
        </para>
        <mediaobject>
            <imageobject>
                <imagedata fileref="matrix.jpg" format="JPG" scale="50" />
            </imageobject>
        </mediaobject>
    </sect1>
    <sect1>
        <title>Human Generated Data and Machine Generated Data</title>
        <para>
            Human Generated Data is emails, documents, photos and tweets.  We are generating this data faster than ever.  Just imagine the number of videos uploaded to You Tube and tweets swirling around.  This data can be Big Data too.
        </para>
        <para>
            Machine Generated Data is a new breed of data.  This category consists of sensor data, and logs generated by 'machines' such as email logs, click stream logs, etc.  Machine generated data is orders of magnitude larger than Human Generated Data.
        </para>
        <para>
            Before 'Hadoop' was in the scene, the machine generated data was mostly ignored and not captured.  It is because dealing with the volume was NOT possible, or NOT cost effective.
        </para>
		<inlinegraphic fileref="bigdata_pyramid1.png" format="PNG" width="100%" scalefit="1" contentdepth="100%" />
    </sect1>
    <sect1>
        <title>Where does Big Data come from</title>
        Original big data was the web data -- as in the entire Internet!  Remember Hadoop was built to index the web.  These days Big data comes from multiple sources.
        <itemizedlist>
            <listitem>
                Web Data -- still it is big data
            </listitem>
            <listitem>
                Social media data : Sites like Facebook, Twitter, LinkedIn generate a large amount of data
            </listitem>
            <listitem>
                Click stream data : when users navigate a website, the clicks are logged for further analysis (like navigation patterns).  Click stream data is important in on line advertising and and E-Commerce
            </listitem>
            <listitem>
                sensor data : sensors embedded in roads to monitor traffic and misc. other applications generate a large volume of data
            </listitem>
            <listitem>
                Connected Devices : Smart phones are a great example.  For example when you use a navigation application like Google Maps or Waze, your phone sends pings back reporting its location and speed (this information is used for calculating traffic hotspots).  Just imagine hundres of millions (or even billions) of devices consuming data and generating data.
            </listitem>
        </itemizedlist>
    </sect1>

    <sect1>
        <title>Examples of Big Data in the Real world</title>
        So how much data are we talking about?
        <itemizedlist>
            <listitem>
                Facebook : has 40 PB of data and captures 100 TB / day
            </listitem>
            <listitem>
                Yahoo : 60 PB of data
            </listitem>
            <listitem>
                Twitter : 8 TB / day
            </listitem>
            <listitem>
                EBay : 40 PB of data, captures 50 TB / day
            </listitem>
        </itemizedlist>
        <figure>
            <title>Tidal Wave of Data</title>
			<inlinegraphic fileref="tidal_wave_of_data_scaled.png" format="PNG"  width="100%" scalefit="1" contentdepth="100%"/>
        </figure>
    </sect1>


    <sect1>
        <title>Challenges of Big Data</title>
        <sect2>
            <title>Sheer size of Big Data</title>
            <para>
                Big data is... well... big in size!  How much data constitute Big Data is not very clear cut.  So lets not get bogged down in that debate.  For a small company that is used to dealing with data in gigabytes,  10TB of data would be BIG.  However for companies like Facebook and Yahoo,  peta bytes is big.
            </para>
            <para>
                Just the size of big data, makes it impossible (or at least cost prohibitive) to store in traditional storage like databases or conventional filers.
            </para>
            <para>
                We are talking about cost to store gigabytes of data.  Using traditional storage filers can cost a lot of money to store Big Data.
            </para>
        </sect2>

        <sect2>
            <title>Big Data is unstructured or semi structured</title>
            <para>
                A lot of Big Data is unstructured.  For example click stream log data might look like
                <code>
                    time stamp, user_id, page, referrer_page
                </code> <sbr/>
                Lack of structure makes relational databases not well suited to store Big Data.
            </para>
            <para>
                Plus, not many databases can cope with storing billions of rows of data.
            </para>
        </sect2>
        <sect2>
            <title>No point in just storing big data, if we can't process it</title>
            <para>
                Storing Big Data is part of the game.  We have to process it to mine intelligence out of it.  Traditional storage systems are pretty 'dumb' as in they just store bits --  They don't offer any processing power.
            </para>
            <para>
                The traditional data processing model has data stored in a 'storage cluster', which is copied over to a 'compute cluster' for processing, and the results are written back to the storage cluster.
            </para>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="storage_compute_1.png" format="PNG" scale="100" />
                </imageobject>
            </mediaobject>
            <para>
                This model however doesn't quite work for Big Data because copying so much data out to a compute cluster might be too time consuming or impossible.  So what is the answer?
            </para>
            <para>
                One solution is to process Big Data 'in place' -- as in a storage cluster doubling as a compute cluster.
            </para>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="storage_compute_2.png" format="PNG" scale="100" />
                </imageobject>
            </mediaobject>
        </sect2>
    </sect1>

    <section>
        <title>
            Taming Big Data
        </title>
        <para>
            So as we have seen above, Big Data defies traditional storage.  So how do we handle Big Data?  In the next chapter we will see about <xref linkend="Hadoop_and_Big_Data"/>
        </para>
    </section>

</chapter>
